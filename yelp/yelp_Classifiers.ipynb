{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-cleaned dataset\n",
    "input_prefix = 'yelp_cleaned'\n",
    "\n",
    "df_train = pd.read_csv(input_prefix + '_train.csv')\n",
    "df_test = pd.read_csv(input_prefix + '_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10261 entries, 0 to 10260\n",
      "Data columns (total 2 columns):\n",
      "target    10261 non-null int64\n",
      "text      10261 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 160.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2054 entries, 0 to 2053\n",
      "Data columns (total 2 columns):\n",
      "target    2054 non-null int64\n",
      "text      2054 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 32.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text back into tokens\n",
    "X_train = [text.split(' ') for text in df_train['text'].astype(str)]\n",
    "X_test = [text.split(' ') for text in df_test['text'].astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split of targets\n",
    "y_train = df_train['target']\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TFIDF vectorizing model\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,6))\n",
    "tfidf_vect_ngram.fit(df_train['text'])\n",
    "\n",
    "# Vectorize text tokens\n",
    "X_train_tfidf =  tfidf_vect_ngram.transform(df_train['text'])\n",
    "X_test_tfidf =  tfidf_vect_ngram.transform(df_test['text'])\n",
    "\n",
    "# Get array of feature names (words) from TFIDF Vectorizer\n",
    "tfidf_feat_names = np.array(tfidf_vect_ngram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample positive judgements to balance classes\n",
    "ros = RandomUnderSampler(random_state=0)\n",
    "X_train_tfidf_us, y_train_tfidf_us = ros.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample positive judgements to balance classes\n",
    "ros = RandomUnderSampler(random_state=0)\n",
    "X_test_tfidf_us, y_test_tfidf_us = ros.fit_resample(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean Vectors:  0.873904576436222\n",
      "F1 Score:  [0.93117194 0.24927536]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1752,  243],\n",
       "       [  16,   43]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Linear Logistic Regression Classifier\n",
    "lr_clf_1 = linear_model.LogisticRegression()\n",
    "\n",
    "# Linear Logistic Regression on TFIDF Vectors\n",
    "lr_model_1 = lr_clf_1.fit(X_train_tfidf_us, y_train_tfidf_us)\n",
    "lr_preds_1 = lr_model_1.predict(X_test_tfidf)\n",
    "\n",
    "lr_accuracy_1 = metrics.accuracy_score(lr_preds_1, y_test)\n",
    "\n",
    "print('LR Mean Vectors: ', lr_accuracy_1)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, lr_preds_1, average=None))\n",
    "metrics.confusion_matrix(y_test, lr_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean Vectors:  0.873904576436222\n",
      "F1 Score:  [0.93117194 0.24927536]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1752,  243],\n",
       "       [  16,   43]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Linear Logistic Regression Classifier\n",
    "lr_clf_1 = linear_model.LogisticRegression()\n",
    "\n",
    "# Linear Logistic Regression on TFIDF Vectors\n",
    "lr_model_1 = lr_clf_1.fit(X_train_tfidf_us, y_train_tfidf_us)\n",
    "lr_preds_1 = lr_model_1.predict(X_test_tfidf)\n",
    "\n",
    "lr_accuracy_1 = metrics.accuracy_score(lr_preds_1, y_test)\n",
    "\n",
    "print('LR Mean Vectors: ', lr_accuracy_1)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, lr_preds_1, average=None))\n",
    "metrics.confusion_matrix(y_test, lr_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Mean Vectors:  0.870983446932814\n",
      "F1 Score:  [0.92942743 0.24929178]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1745,  250],\n",
       "       [  15,   44]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SVC Classifier\n",
    "svc_clf_1 = LinearSVC()\n",
    "\n",
    "# SVC on TFIDF Vectors\n",
    "svc_model_1 = svc_clf_1.fit(X_train_tfidf_us, y_train_tfidf_us)\n",
    "svc_preds_1 = svc_model_1.predict(X_test_tfidf)\n",
    "\n",
    "svc_accuracy_1 = metrics.accuracy_score(svc_preds_1, y_test)\n",
    "\n",
    "print('SVC Mean Vectors: ', svc_accuracy_1)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, svc_preds_1, average=None))\n",
    "metrics.confusion_matrix(y_test, svc_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.8485881207400194\n",
      "F1 Score:  [0.91596866 0.23587224]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1695,  300],\n",
       "       [  11,   48]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Naive Bayes Classifier\n",
    "nb_clf_1 = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Naive Bayes  on TFIDF Vectors\n",
    "nb_model_1 = nb_clf_1.fit(X_train_tfidf_us, y_train_tfidf_us)\n",
    "nb_preds_1 = nb_model_1.predict(X_test_tfidf)\n",
    "\n",
    "nb_accuracy_1 = metrics.accuracy_score(nb_preds_1, y_test)\n",
    "\n",
    "print('NB, Count Vectors: ', nb_accuracy_1)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, nb_preds_1, average=None))\n",
    "metrics.confusion_matrix(y_test, nb_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_preds = np.round(np.mean([nb_preds_1, lr_preds_1, svc_preds_1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  [0.92828579 0.2464986 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1741,  254],\n",
       "       [  15,   44]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('F1 Score: ', metrics.f1_score(y_test, ens_preds, average=None))\n",
    "metrics.confusion_matrix(y_test, ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important words for category 0\n",
      "['pron' 'great' 'good' 'the' 'be' 'place' 'food' 's' 'delicious' 'love'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of the most important words for each category using TFIDF and \n",
    "# the LR model\n",
    "print('Most important words for category 0')\n",
    "print(tfidf_feat_names[np.argsort(-nb_model_1.coef_[0,:])[0:10]], '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample positive judgements to balance classes\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_tfidf_os, y_train_tfidf_os = ros.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean Vectors:  0.9698149951314509\n",
      "F1 Score:  [0.98466106 0.06060606]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1990,    5],\n",
       "       [  57,    2]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Linear Logistic Regression Classifier\n",
    "lr_clf_2 = linear_model.LogisticRegression()\n",
    "\n",
    "# Linear Logistic Regression on TFIDF Vectors\n",
    "lr_model_2 = lr_clf_2.fit(X_train_tfidf_os, y_train_tfidf_os)\n",
    "lr_preds_2 = lr_model_2.predict(X_test_tfidf)\n",
    "\n",
    "lr_accuracy_2 = metrics.accuracy_score(lr_preds_2, y_test)\n",
    "\n",
    "print('LR Mean Vectors: ', lr_accuracy_2)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, lr_preds_2, average=None))\n",
    "metrics.confusion_matrix(y_test, lr_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Mean Vectors:  0.9712755598831548\n",
      "F1 Score:  [0.98541409 0.06349206]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1993,    2],\n",
       "       [  57,    2]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SVC Classifier\n",
    "svc_clf_2 = LinearSVC()\n",
    "\n",
    "# SVC on TFIDF Vectors\n",
    "svc_model_2 = svc_clf_2.fit(X_train_tfidf_os, y_train_tfidf_os)\n",
    "svc_preds_2 = svc_model_2.predict(X_test_tfidf)\n",
    "\n",
    "svc_accuracy_2 = metrics.accuracy_score(svc_preds_2, y_test)\n",
    "\n",
    "print('SVC Mean Vectors: ', svc_accuracy_2)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, svc_preds_2, average=None))\n",
    "metrics.confusion_matrix(y_test, svc_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.9581304771178188\n",
      "F1 Score:  [0.97823887 0.44871795]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1933,   62],\n",
       "       [  24,   35]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Naive Bayes Classifier\n",
    "nb_clf_2 = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Naive Bayes  on TFIDF Vectors\n",
    "nb_model_2 = nb_clf_2.fit(X_train_tfidf_os, y_train_tfidf_os)\n",
    "nb_preds_2 = nb_model_2.predict(X_test_tfidf)\n",
    "\n",
    "nb_accuracy_2 = metrics.accuracy_score(nb_preds_2, y_test)\n",
    "\n",
    "print('NB, Count Vectors: ', nb_accuracy_2)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, nb_preds_2, average=None))\n",
    "metrics.confusion_matrix(y_test, nb_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample positive judgements using SMOTE to balance classes\n",
    "sm = SMOTE(random_state=13)\n",
    "X_train_tfidf_sm, y_train_tfidf_sm = sm.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean Vectors:  0.9698149951314509\n",
      "F1 Score:  [0.98466106 0.06060606]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1990,    5],\n",
       "       [  57,    2]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Linear Logistic Regression Classifier\n",
    "lr_clf_5 = linear_model.LogisticRegression()\n",
    "\n",
    "# Linear Logistic Regression on TFIDF Vectors\n",
    "lr_model_5 = lr_clf_5.fit(X_train_tfidf_sm, y_train_tfidf_sm)\n",
    "lr_preds_5 = lr_model_5.predict(X_test_tfidf)\n",
    "\n",
    "lr_accuracy_5 = metrics.accuracy_score(lr_preds_5, y_test)\n",
    "\n",
    "print('LR Mean Vectors: ', lr_accuracy_5)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, lr_preds_5, average=None))\n",
    "metrics.confusion_matrix(y_test, lr_preds_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Mean Vectors:  0.9712755598831548\n",
      "F1 Score:  [0.98541409 0.06349206]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1993,    2],\n",
       "       [  57,    2]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SVC Classifier\n",
    "svc_clf_5 = LinearSVC()\n",
    "\n",
    "# SVC on TFIDF Vectors\n",
    "svc_model_5 = svc_clf_5.fit(X_train_tfidf_sm, y_train_tfidf_sm)\n",
    "svc_preds_5 = svc_model_5.predict(X_test_tfidf)\n",
    "\n",
    "svc_accuracy_5 = metrics.accuracy_score(svc_preds_5, y_test)\n",
    "\n",
    "print('SVC Mean Vectors: ', svc_accuracy_5)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, svc_preds_5, average=None))\n",
    "metrics.confusion_matrix(y_test, svc_preds_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.939143135345667\n",
      "F1 Score:  [0.96798976 0.38423645]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1890,  105],\n",
       "       [  20,   39]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Naive Bayes Classifier\n",
    "nb_clf_5 = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Naive Bayes  on TFIDF Vectors\n",
    "nb_model_5 = nb_clf_5.fit(X_train_tfidf_sm, y_train_tfidf_sm)\n",
    "nb_preds_5 = nb_model_5.predict(X_test_tfidf)\n",
    "\n",
    "nb_accuracy_5 = metrics.accuracy_score(nb_preds_5, y_test)\n",
    "\n",
    "print('NB, Count Vectors: ', nb_accuracy_5)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, nb_preds_5, average=None))\n",
    "metrics.confusion_matrix(y_test, nb_preds_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,6))\n",
    "count_vect.fit(df_train['text'])\n",
    "\n",
    "# Transform the training and test data using count vectorizer object\n",
    "X_train_count =  count_vect.transform(df_train['text'])\n",
    "X_test_count =  count_vect.transform(df_test['text'])\n",
    "\n",
    "# Get list of feature names (words) from Count Vectorizer\n",
    "count_feat_names = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample positive judgements to balance classes\n",
    "ros = RandomUnderSampler(random_state=0)\n",
    "X_train_count_us, y_train_count_us = ros.fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean Vectors:  0.8354430379746836\n",
      "F1 Score:  [0.90815217 0.21028037]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1671,  324],\n",
       "       [  14,   45]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Linear Logistic Regression Classifier\n",
    "lr_clf_3 = linear_model.LogisticRegression()\n",
    "\n",
    "# Linear Logistic Regression on Count Vectors\n",
    "lr_model_3 = lr_clf_3.fit(X_train_count_us, y_train_count_us)\n",
    "lr_preds_3 = lr_model_3.predict(X_test_count)\n",
    "\n",
    "lr_accuracy_3 = metrics.accuracy_score(lr_preds_3, y_test)\n",
    "\n",
    "print('LR Mean Vectors: ', lr_accuracy_3)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, lr_preds_3, average=None))\n",
    "metrics.confusion_matrix(y_test, lr_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Mean Vectors:  0.8222979552093476\n",
      "F1 Score:  [0.90019141 0.19068736]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1646,  349],\n",
       "       [  16,   43]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SVC Classifier\n",
    "svc_clf_3 = LinearSVC()\n",
    "\n",
    "# SVC on Count Vectors\n",
    "svc_model_3 = svc_clf_3.fit(X_train_count_us, y_train_count_us)\n",
    "svc_preds_3 = svc_model_3.predict(X_test_count)\n",
    "\n",
    "svc_accuracy_3 = metrics.accuracy_score(svc_preds_3, y_test)\n",
    "\n",
    "print('SVC Mean Vectors: ', svc_accuracy_3)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, svc_preds_3, average=None))\n",
    "metrics.confusion_matrix(y_test, svc_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.939143135345667\n",
      "F1 Score:  [0.96810411 0.33862434]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1897,   98],\n",
       "       [  27,   32]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Naive Bayes Classifier\n",
    "nb_clf_3 = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "nb_model_3 = nb_clf_3.fit(X_train_count_us, y_train_count_us)\n",
    "nb_preds_3 = nb_model_3.predict(X_test_count)\n",
    "\n",
    "nb_accuracy_3 = metrics.accuracy_score(nb_preds_3, y_test)\n",
    "\n",
    "print('NB, Count Vectors: ', nb_accuracy_3)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, nb_preds_3, average=None))\n",
    "metrics.confusion_matrix(y_test, nb_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important words for category 0 (guns)\n",
      "['pron' 'great' 'good' 'the' 'be' 'place' 'food' 's' 'not' 'love'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of the most important words for each category using BOW and \n",
    "# the Naive Bayes model\n",
    "print('Most important words for category 0 (guns)')\n",
    "print(tfidf_feat_names[np.argsort(-nb_model_2.coef_[0,:])[0:10]], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample positive judgements to balance classes\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_count_os, y_train_count_os = ros.fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean Vectors:  0.9707887049659202\n",
      "F1 Score:  [0.98514851 0.11764706]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1990,    5],\n",
       "       [  55,    4]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Linear Logistic Regression Classifier\n",
    "lr_clf_4 = linear_model.LogisticRegression()\n",
    "\n",
    "# Linear Logistic Regression on Count Vectors\n",
    "lr_model_4 = lr_clf_4.fit(X_train_count_os, y_train_count_os)\n",
    "lr_preds_4 = lr_model_4.predict(X_test_count)\n",
    "\n",
    "lr_accuracy_4 = metrics.accuracy_score(lr_preds_4, y_test)\n",
    "\n",
    "print('LR Mean Vectors: ', lr_accuracy_4)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, lr_preds_4, average=None))\n",
    "metrics.confusion_matrix(y_test, lr_preds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Mean Vectors:  0.9688412852969815\n",
      "F1 Score:  [0.98415057 0.08571429]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1987,    8],\n",
       "       [  56,    3]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SVC Classifier\n",
    "svc_clf_4 = LinearSVC()\n",
    "\n",
    "# SVC on Count Vectors\n",
    "svc_model_4 = svc_clf_4.fit(X_train_count_os, y_train_count_os)\n",
    "svc_preds_4 = svc_model_4.predict(X_test_count)\n",
    "\n",
    "svc_accuracy_4 = metrics.accuracy_score(svc_preds_4, y_test)\n",
    "\n",
    "print('SVC Mean Vectors: ', svc_accuracy_4)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, svc_preds_4, average=None))\n",
    "metrics.confusion_matrix(y_test, svc_preds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.9712755598831548\n",
      "F1 Score:  [0.98536343 0.23376623]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1986,    9],\n",
       "       [  50,    9]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Naive Bayes Classifier\n",
    "nb_clf_4 = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "nb_model_4 = nb_clf_4.fit(X_train_count_os, y_train_count_os)\n",
    "nb_preds_4 = nb_model_4.predict(X_test_count)\n",
    "\n",
    "nb_accuracy_4 = metrics.accuracy_score(nb_preds_4, y_test)\n",
    "\n",
    "print('NB, Count Vectors: ', nb_accuracy_4)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, nb_preds_4, average=None))\n",
    "metrics.confusion_matrix(y_test, nb_preds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample positive judgements using SMOTE to balance classes\n",
    "sm = SMOTE(random_state=13)\n",
    "X_train_count_sm, y_train_count_sm = sm.fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean Vectors:  0.9284323271665044\n",
      "F1 Score:  [0.96256684 0.1878453 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1890,  105],\n",
       "       [  42,   17]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Linear Logistic Regression Classifier\n",
    "lr_clf_6 = linear_model.LogisticRegression()\n",
    "\n",
    "# Linear Logistic Regression on Count Vectors\n",
    "lr_model_6 = lr_clf_6.fit(X_train_count_sm, y_train_count_sm)\n",
    "lr_preds_6 = lr_model_6.predict(X_test_count)\n",
    "\n",
    "lr_accuracy_6 = metrics.accuracy_score(lr_preds_6, y_test)\n",
    "\n",
    "print('LR Mean Vectors: ', lr_accuracy_6)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, lr_preds_6, average=None))\n",
    "metrics.confusion_matrix(y_test, lr_preds_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Mean Vectors:  0.9259980525803311\n",
      "F1 Score:  [0.9612047 0.2      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1883,  112],\n",
       "       [  40,   19]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SVC Classifier\n",
    "svc_clf_6 = LinearSVC()\n",
    "\n",
    "# SVC on Count Vectors\n",
    "svc_model_6 = svc_clf_6.fit(X_train_count_sm, y_train_count_sm)\n",
    "svc_preds_6 = svc_model_6.predict(X_test_count)\n",
    "\n",
    "svc_accuracy_6 = metrics.accuracy_score(svc_preds_6, y_test)\n",
    "\n",
    "print('SVC Mean Vectors: ', svc_accuracy_6)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, svc_preds_6, average=None))\n",
    "metrics.confusion_matrix(y_test, svc_preds_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.9712755598831548\n",
      "F1 Score:  [0.9854285 0.       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1995,    0],\n",
       "       [  59,    0]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Naive Bayes Classifier\n",
    "nb_clf_6 = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "nb_model_6 = nb_clf_6.fit(X_train_count_sm, y_train_count_sm)\n",
    "nb_preds_6 = nb_model_6.predict(X_test_count)\n",
    "\n",
    "nb_accuracy_6 = metrics.accuracy_score(nb_preds_6, y_test)\n",
    "\n",
    "print('NB, Count Vectors: ', nb_accuracy_6)\n",
    "print('F1 Score: ', metrics.f1_score(y_test, nb_preds_6, average=None))\n",
    "metrics.confusion_matrix(y_test, nb_preds_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  [0.97247706 0.41304348]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1908,   87],\n",
       "       [  21,   38]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_preds = np.argmax(np.mean([nb_clf_1.predict_proba(X_test_tfidf),\n",
    "                                nb_clf_2.predict_proba(X_test_tfidf),\n",
    "                                nb_clf_5.predict_proba(X_test_tfidf)], axis=0), axis=1) + 1\n",
    "\n",
    "print('F1 Score: ', metrics.f1_score(y_test, prob_preds, average=None))\n",
    "metrics.confusion_matrix(y_test, prob_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
