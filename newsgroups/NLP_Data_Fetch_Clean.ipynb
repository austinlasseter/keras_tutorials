{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prefix for all output files\n",
    "output_prefix = '20newsgroups_pols_cleaned_nh'\n",
    "\n",
    "# List categories of articles to grab\n",
    "cats = ['talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the articles from the 20 newsgroup dataset from sklearn\n",
    "train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "test = fetch_20newsgroups(subset='test', categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and testing data to dataframe format\n",
    "df_train = pd.DataFrame(train.data, columns=['text'])\n",
    "df_test = pd.DataFrame(test.data, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split of target data\n",
    "y_train = pd.DataFrame(train.target)\n",
    "y_test = pd.DataFrame(test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1952 entries, 0 to 1951\n",
      "Data columns (total 1 columns):\n",
      "text    1952 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 15.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean each article\n",
    "def clean_text(block):\n",
    "    # Skip header in article (Each header ends with two newlines)\n",
    "    start = block.find('\\n\\n')  \n",
    "    if 0 < start:\n",
    "        block = block[start:]\n",
    "    \n",
    "    # Tokenize the article\n",
    "    doc = nlp(block)\n",
    "    \n",
    "    # New list to append cleaned text to\n",
    "    cleaned = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop: # Don't keep stop words\n",
    "            if not token.is_punct: # Don't keep punctuation\n",
    "                cleaned.append(token.lemma_) # Keep lemma for each remaining token\n",
    "    \n",
    "    # Remove other punctuation missed earlier and join into a sentence\n",
    "    cleaned = ' '.join(cleaned).replace('>', '').replace('<', '').replace('^', '').replace('\\n', '').replace('\\t', '').replace('|', '').strip()\n",
    "    \n",
    "    # Remove excess whitespace between words\n",
    "    return ' '.join(cleaned.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 % finished\n",
      "10 % finished\n",
      "15 % finished\n",
      "20 % finished\n",
      "25 % finished\n",
      "30 % finished\n",
      "35 % finished\n",
      "40 % finished\n",
      "45 % finished\n",
      "50 % finished\n",
      "55 % finished\n",
      "60 % finished\n",
      "65 % finished\n",
      "70 % finished\n",
      "75 % finished\n",
      "80 % finished\n",
      "85 % finished\n",
      "90 % finished\n",
      "95 % finished\n",
      "100 % finished\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the training dataframe to save cleaned data to\n",
    "df_train_cp = df_train.copy()\n",
    "\n",
    "# Loop through and clean all articles\n",
    "per = 5\n",
    "for i, text in enumerate(df_train.text):\n",
    "    df_train_cp.text[i] = clean_text(text)\n",
    "    \n",
    "    if int(i*100/len(df_train)) == per:\n",
    "        print(per, '% finished')\n",
    "        per += 5\n",
    "print('100 % finished')\n",
    "\n",
    "# Join target data back to cleaned dataframe and save\n",
    "df_train_tot = df_train_cp.copy()\n",
    "df_train_tot['target'] = y_train[0]\n",
    "\n",
    "outfile_1 = output_prefix + '_train.csv'\n",
    "df_train_tot.to_csv(outfile_1)\n",
    "\n",
    "print('training data saved to', outfile_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 % finished\n",
      "10 % finished\n",
      "15 % finished\n",
      "20 % finished\n",
      "25 % finished\n",
      "30 % finished\n",
      "35 % finished\n",
      "40 % finished\n",
      "45 % finished\n",
      "50 % finished\n",
      "55 % finished\n",
      "60 % finished\n",
      "65 % finished\n",
      "70 % finished\n",
      "75 % finished\n",
      "80 % finished\n",
      "85 % finished\n",
      "90 % finished\n",
      "95 % finished\n",
      "100 % finished\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the training dataframe to save cleaned data to\n",
    "df_test_cp = df_test.copy()\n",
    "\n",
    "# Loop through and clean all articles\n",
    "per = 5\n",
    "for i, text in enumerate(df_test.text):\n",
    "    df_test_cp.text[i] = clean_text(text)\n",
    "    \n",
    "    if int(i*100/len(df_test)) == per:\n",
    "        print(per, '% finished')\n",
    "        per += 5\n",
    "print('100 % finished')\n",
    "\n",
    "# Join target data back to cleaned dataframe and save\n",
    "df_test_tot = df_test_cp.copy()\n",
    "df_test_tot['target'] = y_test[0]\n",
    "\n",
    "outfile_2 = output_prefix + '_test.csv'\n",
    "df_test_tot.to_csv(outfile_2)\n",
    "\n",
    "print('test data saved to', outfile_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
